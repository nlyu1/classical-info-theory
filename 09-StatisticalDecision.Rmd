# Statistical Decision Applications 

Key takeaways:

1. $R_\theta(\hat \theta)$ is the expectation of loss over $X\sim P_\theta$. 
2. There are two ways turn $R_\theta(\hat\theta)$ into a scalar: 
    - Eliminating $\theta$ with $\sup_\theta$, then taking $\inf$ 
    over all estimators leads to the minimax risk $R^*$. 
    - Replacing $\theta$ by averaging over a prior $\pi$, 
    taking $\inf$ over $\hat \theta$, then taking $\sup_\pi$ adversarially 
    over all priors $\pi$ leads to the Bayes risk. 
3. The minimax and Bayes risks are related by [duality](minimaxDual). 
4. Under mild assumptions, $R^* = R^*_{\mrm{Bayes}}$. 
    

## Minimax and Bayes risks {-}

- A **statistical model** is a collection 
    $\mca P = \{P_\theta:\theta \in \Theta\}$ of distributions 
    over some measurable space $(\mca X, \Sigma)$. 
    Here $\Theta$ is the **parameter space**. 
- An **estimand** $T(\theta)$ has signature $T:\Theta\to \mca Y$; 
    in the trivial case $T$ is just the identity. 
- An **estimator** (decision rule) has type $\hat T:\Omega\to \hat {\mca Y}$. 
    The action space $\hat {\mca Y}$ does not have to be 
    the estimand space $\mca Y$ (e.g. when we're estimating a confidence interval). 
    - $\hat T$ can be deterministic or randomized. 
- To evaluate the estimator, the **loss function** $l:\mca Y\times \hat{\mca Y}\to \R$ 
    defines the **risk** of $\hat T$ for estimating $T$. 
- The (expected) risk of the estimator $\hat T$ for estimating $T$ is 
    <span style="color:green">a function of the true parameter $\theta$ 
    and estimator $\hat T$ </span>: 
\[ 
    R_\theta(\hat T) 
    = \Exp_{X\sim \theta}[l(T(\theta), \hat T(X)] 
    = \int P_\theta(dx) P_{\hat T|X}(\hat t|x) l(T(\theta), \hat t)
\] 

Two comments in order: 

- For the minimax risk, it is sometimes necessary to 
randomize. To minimize the average risk over a prior (Bayesian approach), 
though, it suffices to consider deterministic functions. 
- The space of randomized estimators (as Markov kernels) is convex. 
This is necessary for minimax theorems. 
- For $\hat T\mapsto l(T, \hat T)$ convex, we can derandomize 
    it by consider $\Exp[\hat T|X]$, then 
    \[ 
        R_\theta(\hat T) = \Exp_\theta l(T, \hat T) \geq 
        \Exp_\theta l(T, \Exp[\hat T|X])
    \] 

:::{.definition name="Bayes risk"}
Given a prior $\pi$, the average risk w.r.t. $\pi$ 
of an estimator is 
\[ 
    R_\pi(\hat \theta) 
    = \Exp_{\theta \sim \pi} R_\theta(\hat \theta) 
    = \Exp_{\theta \sim \pi, X\sim P_\theta} l(\theta, \hat \theta(X))
\] 
The **Bayes risk** of a prior is its minimal average risk 
$R_\pi^* = \inf_{\hat \theta} R_\pi(\hat \theta)$. 
The optimal $\hat \theta$ is the Bayes estimator. 
:::

:::{.definition name="minimax risk"}
Given a parameter family $P_{\theta\in \Theta}$ and 
loss function $l$, the minimax risk is  
\[ 
    R^* = \inf_{\hat \theta} \sup_{\theta \in \Theta} 
    R_\theta(\hat \theta) 
    = \inf_{\hat \theta} \sup_{\theta \in \Theta} 
    \Exp_{X\sim P_\theta} l(\hat \theta(X), \theta)
\] 
To prove minimax risk, one needs to establish for arbitrary $\epsilon$ 

1. an estimator $\hat \theta^*$ satisfying 
    $R_\theta(\hat \theta^*)\leq R^*+\epsilon$. 
2. For arbitrary $\hat \theta$, 
    $\sup_{\theta} R_\theta(\hat \theta)\geq R^*-\epsilon$. 
:::


:::{.theorem name="duality between minimax and Bayes risk"}
Let $\mca P(\Theta)$ denote the set of probability distributions 
on $\Theta$, then 
\[ 
    R^* = \inf_{\hat \theta}\sup_{\theta \in \Theta} R_\theta(\hat \theta)
    \geq R^*_{\mrm{Bayes}} 
    = \sup_{\pi \in \mca P(\theta)} \inf_{\hat \theta} 
    R_\pi(\hat \theta)
\] 
:::
_Proof:_ $R^* = \inf_{\hat \theta}\sup_{\theta \in \Theta} R_\theta(\hat \theta)
= \inf_{\hat \theta}\sup_{\pi \in \mca P(\Theta)} R_\pi(\hat \theta)
\geq R^*_{\mrm{Bayes}}$ by $\inf\sup \geq \sup\inf$. 

:::{.example name="strict inequality"}
Let $\theta, \hat \theta \in \{1, 2, \cdots\}$ and 
$l(\theta, \hat \theta) = 1_{\hat \theta < \theta}$, then 
$R^* = 1$ while $R^*_{\mrm{Bayes}} = 0$. 
:::

## A duality perspective {#minimaxDual -}

For simplicity, let $\Theta$ be a finite set and $l$ be convex, then 
\[ 
    R^* = \min_{P_{\hat \theta|X}} \max_{\theta \in \Theta} 
    \Exp_\theta \, l(\theta, \hat \theta)
\] 
This is a convex optimization problem since 
$P_{\hat \theta|X}\mapsto \Exp_\theta \, l(\theta, \hat \theta)$ 
is convex and the supremum of affine functions is convex. 
Considering its dual, rewrite 
\[ 
    R^* = \min_{P_{\hat \theta|X}, t} \, t\quad \text{s.t. } 
    \Exp_\theta\, l(\theta, \hat \theta) \leq t, \quad \forall \theta \in \Theta 
\] 
Let $\pi_\theta\geq 0$ for each inequality constraint. 
The Lagrangian is 
\[ 
    \mca L(P_{\hat \theta|X}, t, \pi) 
    = t + \sum_{\theta \in \Theta} \pi_\theta\cdot \left(
        \Exp_\theta\, l(\theta, \hat \theta) - t 
    \right) = \left(
        1 - \sum_{\theta \in \Theta} \pi_\theta 
    \right)t + \sum_{\theta \in \Theta} \pi_\theta \Exp_\theta\, l(\theta, \hat \theta)
\] 
The first term implies that $\pi$ must be a probability measure, 
yielding the dual problem 
\[ 
    \max_\pi \min_{P_{\hat \theta|X}} 
    \sum_{\theta \in \Theta} \pi_\theta \Exp_\theta\, l(\theta, \hat \theta)
    = \max_{\pi \in \mca P(\Theta)} R_\pi^*
\] 

:::{.theorem name="general minimax equality"}
$R^* = R^*_{\mrm{Bayes}}$ if the following conditions hold: 

1. The experiment is dominated: $P_{\forall \theta} \ll \nu$ for some $\nu$. 
2. The action space $\hat \Theta$ (codomain of the estimator) 
    is a locally compact topological space with a countable basis. 
3. The loss function is level compact: for each $\theta\in \Theta, l(\theta, \cdot)$
    is bounded from below and $\{\hat \theta:l(\theta, \hat \theta)\leq a\}$ 
    is compact for each $a$. 
:::

We will prove the following special case for demonstration. 

:::{.proposition name="special minimax equality"}
$R^* = R^*_{\mrm{Bayes}}$ if 
$\Theta$ is finite and $l$ is bounded from below for all $\theta, \hat \theta$. 
:::

First consider the edge case $R^*=\infty \iff R^*_{\mrm{Bayes}} = \infty$; 
this is established by considering the uniform prior $\pi$ on $\Theta$. 